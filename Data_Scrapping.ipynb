{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <span style=\"color:red\">I. Data Scrapping From YouTube</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.Why Scrapping YouTube"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <span style=\"color:green\">YouTube API </span> vs <span style=\"color:green\">YouTube scraping</span>\n",
    "\n",
    "**YouTube Data API** is the official way to get data from the platform, including information about videos, playlists, and content creators. However, there are at least three good reasons why **scraping YouTube** is better than relying solely on its API:\n",
    "\n",
    "-**Flexibility and Customization**: With a YouTube spider, you can tailor the code to select only the data you need. This level of customization helps you collect the exact information for your specific use case. In contrast, the API only gives you access to predefined data.\n",
    "-**Access to unofficial data**: The API provides access to specific sets of data selected by YouTube. This means that some data you currently rely on May no longer be available in the future. Web scraping allows you instead to obtain any additional information available on the YouTube website, even if not exposed through the API.\n",
    "-**No limitation**: YouTube APIs are subject to rate limiting. This restriction determine the frequency and volume of requests that you can make in a given time frame. By interacting directly with the platform, you can circumvent any limitation.\n",
    "\n",
    "\n",
    "In our Project we need the all comments and their authors, so we have no filters for the comments we will select it all, so we will use YouTube Api"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Scraping YouTube With GoogleApiClient\n",
    "\n",
    "**GoogleApiClient**: The google-api-python-client library is a Python client library for accessing Google's APIs. It provides an easy-to-use interface for interacting with various Google services programmatically, such as YouTube, Google Drive, Gmail, Google Calendar, Google Sheets, and many others.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Library Importation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install google-api-python-client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style='color:blue'>How To Get The API KEY From Google Cloud Console</span>\n",
    "![# API_KEY](images/11.png)\n",
    "![# API_KEY-](images/12.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Set up YouTube API service\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "API_KEY = \"AIzaSyAQtdqS9bIEj0_-Uk3eWTLLxczpUqIxYqE\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=API_KEY)\n",
    "\n",
    "# Function to retrieve all comments from a video\n",
    "def get_all_comments(video_id):\n",
    "    video_info = youtube.videos().list(part=\"snippet\",id=video_id).execute()\n",
    "    comments = []\n",
    "    video_title = video_info['items'][0]['snippet']['title']\n",
    "\n",
    "    nextPageToken = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId= video_id,\n",
    "            maxResults=100,  # Max results per page (default is 100, maximum is 100)\n",
    "            pageToken=nextPageToken\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append({\n",
    "                'Video Title': video_title,\n",
    "                'Author_Name': comment['authorDisplayName'],\n",
    "                'Like_Count': comment.get('likeCount', 0),\n",
    "                'Comment': comment['textDisplay']\n",
    "            })\n",
    "\n",
    "        nextPageToken = response.get('nextPageToken')\n",
    "        if not nextPageToken:\n",
    "            break  # No more pages\n",
    "\n",
    "    return comments\n",
    "\n",
    "video_ids = ['Li9PVsGp1wo','MUl_d-rkQ7k','b_jjw9wVYJw']\n",
    "all_comments = []\n",
    "\n",
    "for i in range(len(video_ids)):\n",
    "    all_comments.extend(get_all_comments(video_ids[i]))\n",
    "\n",
    "# Convert comments data to DataFrame\n",
    "comments_df = pd.DataFrame(all_comments)\n",
    "\n",
    "# Save DataFrame to CSV file with labeled columns\n",
    "comments_df.to_csv('youtube_comments.csv',encoding='utf-8-sig',index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T16:19:05.124366600Z",
     "start_time": "2024-03-25T16:18:47.202559700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "31240"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T16:20:47.162334700Z",
     "start_time": "2024-03-25T16:20:47.155815700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# the most liked comment\n",
    "df_sorted = comments_df.sort_values(by='Like_Count',ascending=False)\n",
    "most_liked = df_sorted.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T16:21:51.205355900Z",
     "start_time": "2024-03-25T16:21:51.201350900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Video Title                                      Psyco M - Plume\nAuthor_Name                                       @ehapfoaad7403\nLike_Count                                                  2404\nComment        ياخي تعلمت اللهجة التونسية لاجلك ولاجل اني افه...\nName: 4387, dtype: object"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_liked"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T16:21:54.208239800Z",
     "start_time": "2024-03-25T16:21:54.203716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
